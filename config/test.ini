[model]
# Size of the import numpy as input
image_size = 13

# Type of prior distribution
#   hypersphere, normal
prior_type = hypersphere

# Type of encoding
#   fc, conv
encoding_type = inception
decoding_type =  inception

# Dimension of the latent space
dim_z = 40

normalize = off

[architecture]
# Path of output images
results_path = results

# Path to store trained graph and tensorboard stuffs
model_path = model

[train]
# Learning rate for Adam optimizer
learn_rate = 1e-3

# The number of epochs to run
num_epochs = 150

batch_size = 256

# Number of trainings of vae, discr and generation per epoch
n_vae_train = 1
n_discr_train = 1
n_gen_train = 1


[plot]
# Boolean for plot-reproduce-result
PRR = off

# Number of images along x-axis
PRR_n_img_x = 10

# Number of images along y-axis
PRR_n_img_y = 10

# Resize factor for each displayed image
PRR_resize_factor = 1.0

# Boolean for plot-manifold-learning-result
PMLR = off

# Number of images along x-axis
PMLR_n_img_x = 15

# Number of images along y-axis
PMLR_n_img_y = 15

# Resize factor for each displayed image
PMLR_resize_factor = 1.0

# Range for unifomly distributed latent vector
PMLR_z_range = 3.0

# Number of samples in order to get distribution of labeled data
PMLR_n_samples = 1000 

[data]

train_dir = data/train_mfcc/
dev_dir = data/dev_mfcc/
test_dir = data/test_mfcc/

train_nb = 5
test_nb = 10
